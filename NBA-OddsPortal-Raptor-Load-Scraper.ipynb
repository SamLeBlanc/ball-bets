{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36609ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "import chromedriver_autoinstaller\n",
    "\n",
    "import time\n",
    "import random\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "import missingno as ms\n",
    "from plotnine import *\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 999)\n",
    "pd.set_option('display.max_columns', 999)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8db097",
   "metadata": {},
   "source": [
    "## Contents:\n",
    "- Set Selenium options\n",
    "- Scrape OddsPortal URLs of all NBA Games in a season [saved to .txt file]\n",
    "- Scrape Bookmaker data from OP URLs into dataframe [saved to pickle]\n",
    "- Transform Bookmaker dataframe\n",
    "- Join NBA team identifiers (needed to join to RAPTOR)\n",
    "- Join RAPTOR scores downloaded from 538"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad010f92",
   "metadata": {},
   "source": [
    "### Set Selenium Options \n",
    "Important! so that OddsPortal is signed in to Sam's account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4deec536",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_path = r'C:\\Users\\sleblanc\\AppData\\Local\\Google\\Chrome\\User Data'\n",
    "profile_name = 'Profile 3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be19655",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_chrome_options():\n",
    "    \"\"\"\n",
    "    Set options for the Chrome webdriver used by Selenium.\n",
    "    Most importantly, set the user data directory and user profile to utilize Chrome's saved passwords.\n",
    "    ----------------\n",
    "    Returns: webdriver.ChromeOptions: Configured Chrome webdriver options.\n",
    "    \"\"\"\n",
    "    profile_path = r'C:\\Users\\sleblanc\\AppData\\Local\\Google\\Chrome\\User Data'\n",
    "    profile_name = 'Profile 3'\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(f'user-data-dir={profile_path}')\n",
    "    options.add_argument(f'--profile-directory={profile_name}')\n",
    "    return options\n",
    "\n",
    "\n",
    "def kill_chrome_processes():\n",
    "    \"\"\"\n",
    "    Terminate all running Chrome processes.\n",
    "    Selenium may encounter issues if there are multiple Chrome instances running,\n",
    "    especially when using a Chrome profile for saved passwords. This function\n",
    "    terminates all Chrome processes (using the subprocess module), including\n",
    "    previous Selenium instances.\n",
    "    \"\"\"\n",
    "    subprocess.call(\"TASKKILL /f  /IM  CHROME.EXE\", stdout=subprocess.DEVNULL, stderr=subprocess.STDOUT)\n",
    "\n",
    "\n",
    "def get_webdriver():\n",
    "    \"\"\"\n",
    "    Instantiate and return a Selenium Chrome webdriver with custom options.\n",
    "    ----------------\n",
    "    Returns:\n",
    "        webdriver.Chrome: Configured Chrome webdriver instance.\n",
    "        False if an exception occurs during instantiation.\n",
    "    Note:\n",
    "        The webdriver must be downloaded and added to PATH. See:\n",
    "        https:/selenium-python.readthedocs.io/installation.html\n",
    "    \"\"\"\n",
    "    try:\n",
    "        chromedriver_autoinstaller.install()\n",
    "        kill_chrome_processes()\n",
    "        options = set_chrome_options()\n",
    "        driver = webdriver.Chrome(options=options)\n",
    "        return driver\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13406918",
   "metadata": {},
   "source": [
    "## Scrape OddsPortal URLs of All NBA Games in a Season\n",
    "Done: [saved to .txt file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb81d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_page(driver, retries=5):\n",
    "    \"\"\"\n",
    "    Load the content of a page by scrolling to the bottom multiple times.\n",
    "    ----------------\n",
    "    Args:\n",
    "        driver (webdriver): The Selenium webdriver instance to interact with the page.\n",
    "        retries (int, optional): The number of times to scroll to the bottom. Defaults to 5.\n",
    "    \"\"\"\n",
    "    for _ in range(retries):\n",
    "        driver.execute_script(\"window.scrollTo(0, 0);\")\n",
    "        time.sleep(1)\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(1)\n",
    "\n",
    "def extract_game_hrefs(driver, season, remove_hrefs):\n",
    "    \"\"\"\n",
    "    Extract the game links from the current page of the NBA season results.\n",
    "    ----------------\n",
    "    Args:\n",
    "        driver (webdriver): The Selenium webdriver instance to interact with the page.\n",
    "        season (str): The NBA season in the format \"YYYY-YYYY\".\n",
    "        remove_hrefs (list): A list of URLs to exclude from the result.\n",
    "    Returns:\n",
    "        set: A set of URLs for individual games in the specified NBA season.\n",
    "    \"\"\"\n",
    "    hrefs = [x.get_attribute(\"href\") for x in driver.find_elements_by_tag_name(\"a\")]\n",
    "    game_hrefs = set(x for x in hrefs if f'nba-{season}' in x and x not in remove_hrefs)\n",
    "    return game_hrefs\n",
    "\n",
    "\n",
    "def click_next_page(driver):\n",
    "    \"\"\"\n",
    "    Click the \"Next\" button to navigate to the next page of the NBA season results.\n",
    "    ----------------\n",
    "    Args: driver (webdriver): The Selenium webdriver instance to interact with the page.\n",
    "    Raises: Exception: If the \"Next\" button is not found on the page.\n",
    "    \"\"\"\n",
    "    driver.find_elements_by_class_name(\"h-max\")[1].click()\n",
    "\n",
    "\n",
    "def scrape_season(season, max_pages=30):\n",
    "    \"\"\"\n",
    "    Scrape game links from the NBA season results page on OddsPortal.\n",
    "    ----------------\n",
    "    Args:\n",
    "        season (str, optional): The NBA season to scrape. Defaults to \"2021-2022\".\n",
    "        max_pages (int, optional): Maximum number of pages to scrape. Defaults to 30.\n",
    "    Returns:\n",
    "        list: A list of URLs for individual games in the specified NBA season.\n",
    "    \"\"\"\n",
    "    all_game_urls = set()\n",
    "    url_base = \"https://www.oddsportal.com/basketball/usa/\"\n",
    "    \n",
    "    url = f\"{url_base}nba-{season}/results/#\"\n",
    "    driver = get_webdriver()\n",
    "    driver.get(url)\n",
    "\n",
    "    for n in range(1, max_pages + 1):    \n",
    "        time.sleep(0.5 + 2 * random.random())\n",
    "        load_page(driver)\n",
    "\n",
    "        remove_hrefs = [\n",
    "            f'https://www.oddsportal.com/basketball/usa/nba-{season}/results/#',\n",
    "            f'https://www.oddsportal.com/basketball/usa/nba-{season}/results/',\n",
    "            f'https://www.oddsportal.com/basketball/usa/nba-{season}/',\n",
    "            f'https://www.oddsportal.com/basketball/usa/nba-{season}/standings/',\n",
    "        ]\n",
    "\n",
    "        game_urls = extract_game_hrefs(driver, season, remove_hrefs)\n",
    "        all_game_urls.update(game_urls)\n",
    "\n",
    "        print(f'Page {n} Finished: Added {len(game_urls)} new games. Total Games: {len(all_game_urls)}')\n",
    "        \n",
    "        try:\n",
    "            click_next_page(driver)\n",
    "        except Exception as e:\n",
    "            print(f\"Next Page Error; closing driver\")\n",
    "            driver.quit()\n",
    "            return list(all_game_urls)\n",
    "\n",
    "    driver.quit()\n",
    "    return list(all_game_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4d97ea",
   "metadata": {},
   "source": [
    "## Scrape ðŸ¥·"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247bacb0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "season = \"2019-2020\"\n",
    "\n",
    "all_game_urls = scrape_season(season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee08244b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# save url list to text file for later\n",
    "with open(f'all_game_urls_{season}.txt', 'w') as file:\n",
    "    for item in all_game_urls:\n",
    "        file.write(item + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ceed1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load url list from file\n",
    "with open(f'all_game_urls_{season}.txt', 'r') as file:\n",
    "    all_game_urls = [line.strip() for line in file.readlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d2d5d3",
   "metadata": {},
   "source": [
    "## Create Bookmaker dataframes from OP URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aad890b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def game_to_df(driver, game_info_xpath, odds_xpath):\n",
    "    \"\"\"\n",
    "    Extract game and odds information from a webpage and return it as a DataFrame.\n",
    "    ----------------\n",
    "    Args:\n",
    "        driver (WebDriver): Selenium WebDriver instance.\n",
    "        game_info_xpath (str): XPath for the game information element.\n",
    "        odds_xpath (str): XPath for the odds information element.\n",
    "    Returns: \n",
    "        pd.DataFrame: DataFrame containing game and odds information.\n",
    "    \"\"\"\n",
    "    \n",
    "    def get_game_info():\n",
    "        \"\"\"\n",
    "        Extract game information from the webpage using the given XPath.\n",
    "        ----------------\n",
    "        Returns: dict: Dictionary containing game information.\n",
    "        \"\"\"\n",
    "        game_info_el = driver.find_element(By.XPATH, game_info_xpath)\n",
    "        game_info_list = game_info_el.text.split('\\n')\n",
    "        \n",
    "        format_string = '%A, %d %b %Y, %H:%M'\n",
    "        game_time = game_info_list[5]\n",
    "        \n",
    "        return {\n",
    "            'Game_Time' : datetime.strptime(game_time, format_string).strftime('%Y-%m-%d %H:%M'),\n",
    "            'Home_Name' : game_info_list[0],\n",
    "            'Away_Name' : game_info_list[3],\n",
    "            'Game_Result' : game_info_list[7],\n",
    "            'Home_Score' : game_info_list[1],\n",
    "            'Away_Score' : game_info_list[4],\n",
    "        }\n",
    "    \n",
    "    def get_odds_info():\n",
    "        \"\"\"\n",
    "        Extract odds information from the webpage using the given XPath.\n",
    "        ----------------\n",
    "        Returns: list: List containing odds information.\n",
    "        \"\"\"\n",
    "        odds_el = driver.find_element(By.XPATH, odds_xpath)\n",
    "\n",
    "        odds_list = odds_el.text.split('\\n')\n",
    "        odds_list = [x for x in odds_list if x != 'BONUS']\n",
    "        odds_list = odds_list[4:odds_list.index('Average')]\n",
    "        \n",
    "        return odds_list\n",
    "    \n",
    "    def get_odds_array(odds_list):\n",
    "        \"\"\"\n",
    "        Convert the odds list into a NumPy array.\n",
    "        ----------------\n",
    "        Args: odds_list (list): List containing odds information.\n",
    "        Returns: np.array: NumPy array of odds information, or False if the list length is not divisible by 4.\n",
    "        \"\"\"\n",
    "        if len(odds_list) % 4 == 0:\n",
    "            rows = int(len(odds_list) / 4)\n",
    "            odds_array = np.array(odds_list).reshape(rows, 4)\n",
    "            return odds_array\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    # get the game info and odds\n",
    "    try:\n",
    "        game_summary = get_game_info()    \n",
    "        odds_list = get_odds_info()    \n",
    "        odds_array = get_odds_array(odds_list)\n",
    "\n",
    "        # create dataframe of bookmaker odds \n",
    "        df = pd.DataFrame(odds_array, columns=['Bookmaker', 'Home_Amer', 'Away_Amer', 'Full_Payout'])\n",
    "\n",
    "        # set the game summary values for all bookmaker rows in dataframe\n",
    "        for key in game_summary:\n",
    "            df[key] = game_summary[key]\n",
    "\n",
    "        # reorder dataframe columns\n",
    "        df = df[[\n",
    "            'Game_Time', 'Home_Name', 'Away_Name', 'Game_Result', 'Home_Score', 'Away_Score',\n",
    "            'Bookmaker', 'Home_Amer', 'Away_Amer', 'Full_Payout']]\n",
    "\n",
    "        return df\n",
    "    except:\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79af9ad8",
   "metadata": {},
   "source": [
    "## Scrape ðŸ¥·"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b501ef5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Element XPATHs, subject to change\n",
    "game_info_xpath = \"/html/body/div[1]/div/div[1]/div/main/div[2]/div[3]\"\n",
    "odds_xpath = \"/html/body/div[1]/div/div[1]/div/main/div[2]/div[4]\"\n",
    "\n",
    "driver = get_webdriver()\n",
    "# bookmaker = pd.DataFrame()\n",
    "for i, url in enumerate(all_game_urls[0:610]):\n",
    "    if i % 10 == 0: print(f\"Finished scraping {i} games out of {len(all_game_urls)}\")\n",
    "    \n",
    "    # Scrape Home/Away odds data\n",
    "    driver.get(url + '/#home-away;1')\n",
    "    \n",
    "    # Random sleep so no DDOS\n",
    "    time.sleep(1 + 2*random.random())\n",
    "\n",
    "    # Get bookmaker data from single game into dataframe\n",
    "    df_ = game_to_df(driver, game_info_xpath, odds_xpath)\n",
    "    \n",
    "    if len(df_) < 1:\n",
    "        print(\"Skipped:\", url)\n",
    "    else:\n",
    "        # Concat with full dataframe\n",
    "        bookmaker = pd.concat([bookmaker, df_])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc9605b",
   "metadata": {},
   "source": [
    "### 2020-2021 Skips\n",
    "\n",
    "Skipped: https://www.oddsportal.com/basketball/usa/nba-2020-2021/houston-rockets-utah-jazz-GKC2XbS9/\n",
    "Skipped: https://www.oddsportal.com/basketball/usa/nba-2020-2021/memphis-grizzlies-san-antonio-spurs-GtlhmSW6/\n",
    "Skipped: https://www.oddsportal.com/basketball/usa/nba-2020-2021/portland-trail-blazers-atlanta-hawks-rsXfJ2zH/\n",
    "Skipped: https://www.oddsportal.com/basketball/usa/nba-2020-2021/dallas-mavericks-utah-jazz-KfxdwcKJ/\n",
    "Skipped: https://www.oddsportal.com/basketball/usa/nba-2020-2021/memphis-grizzlies-los-angeles-clippers-INe1o4Ct/\n",
    "Skipped: https://www.oddsportal.com/basketball/usa/nba-2020-2021/toronto-raptors-charlotte-hornets-W86EQrg4/\n",
    "Skipped: https://www.oddsportal.com/basketball/usa/nba-2020-2021/phoenix-suns-philadelphia-76ers-dflFs7gF/\n",
    "Skipped: https://www.oddsportal.com/basketball/usa/nba-2020-2021/detroit-pistons-new-york-knicks-6XicM4qS/\n",
    "Skipped: https://www.oddsportal.com/basketball/usa/nba-2020-2021/san-antonio-spurs-houston-rockets-2RyzOQLo/\n",
    "\n",
    "### 2021-2022 Skips\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621b0b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bookmaker.drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6a1200",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bookmaker.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bef9800",
   "metadata": {},
   "outputs": [],
   "source": [
    "bookmaker = bookmaker.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0594874d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bookmaker.to_pickle('bookmaker_{season}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02135bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "bookmaker = pd.read_pickle('bookmaker.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1360f0f2",
   "metadata": {},
   "source": [
    "## Transform Bookmaker Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508b9fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def implied_odds_from_american(american_odds):\n",
    "    \"\"\"\n",
    "    Calculate implied odds from American odds.\n",
    "    ----------------\n",
    "    Args: american_odds (int or str): American odds value.\n",
    "    Returns: float: Implied odds.\n",
    "    Raises: ValueError: If the absolute value of American odds is less than 100.\n",
    "    \"\"\"\n",
    "    american_odds = int(american_odds)\n",
    "    if abs(american_odds) < 100:\n",
    "        raise ValueError(f\"American odds must always have absolute value over 100. Supplied odds: {american_odds}\")\n",
    "\n",
    "    if american_odds < 0:\n",
    "        return -american_odds / (-american_odds + 100)\n",
    "    return 100 / (american_odds + 100)\n",
    "\n",
    "def prediction_from_implied_odds(row):\n",
    "    \"\"\"\n",
    "    Predict the winning team based on implied odds.\n",
    "    ----------------\n",
    "    Args: row (dict): A dictionary containing 'Home_Imp' and 'Away_Imp' keys.\n",
    "    Returns: str or None: 'Home' if Home has higher implied odds, 'Away' if Away has higher implied odds, and None if tied.\n",
    "    \"\"\"\n",
    "    home_implied_odds = row['Home_Imp']\n",
    "    away_implied_odds = row['Away_Imp']\n",
    "    \n",
    "    if home_implied_odds > away_implied_odds:\n",
    "        return 'Home'\n",
    "    elif away_implied_odds > home_implied_odds:\n",
    "        return 'Away'\n",
    "    return None\n",
    "\n",
    "def actual_winner(row):\n",
    "    \"\"\"\n",
    "    Determine the actual winner based on the scores.\n",
    "    ----------------\n",
    "    Args: row (dict): A dictionary containing 'Home_Score' and 'Away_Score' keys.\n",
    "    Returns: str or None: 'Home' if Home has a higher score, 'Away' if Away has a higher score, and None if tied.\n",
    "    \"\"\"\n",
    "    home_score = int(row['Home_Score'])\n",
    "    away_score = int(row['Away_Score'])\n",
    "    \n",
    "    if home_score > away_score:\n",
    "        return 'Home'\n",
    "    elif away_score > home_score:\n",
    "        return 'Away'\n",
    "    return None\n",
    "\n",
    "def calculate_brier_score(row):\n",
    "    \"\"\"\n",
    "    Calculate the Brier score for the given row.\n",
    "    ----------------\n",
    "    Args: row (dict): A dictionary containing 'Pred_Winner', 'Actual_Winner', 'Home_Imp', and 'Away_Imp' keys.\n",
    "    Returns: float or np.nan: Brier score if both prediction and actual winner are not None, otherwise np.nan.\n",
    "    \"\"\"\n",
    "    predicted_winner = row['Pred_Winner']\n",
    "    actual_winner = row['Actual_Winner']\n",
    "    \n",
    "    if not predicted_winner or not actual_winner:\n",
    "        return np.nan\n",
    "\n",
    "    if predicted_winner == actual_winner:\n",
    "        return (row[f'{predicted_winner}_Imp'] - 1) ** 2\n",
    "    return row[f'{predicted_winner}_Imp'] ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a58edc8",
   "metadata": {},
   "source": [
    "### Apply transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd588cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bookmaker['date'] = pd.to_datetime(bookmaker['Game_Time'], format='%Y-%m-%d %H:%M').dt.date\n",
    "bookmaker['date'] = bookmaker['date'].apply(lambda x: x.strftime('%Y-%m-%d'))\n",
    "\n",
    "bookmaker['Home_Imp'] = bookmaker['Home_Amer'].apply(implied_odds_from_american)\n",
    "bookmaker['Away_Imp'] = bookmaker['Away_Amer'].apply(implied_odds_from_american)\n",
    "bookmaker['Total_Imp'] = bookmaker['Home_Imp'] + bookmaker['Away_Imp']\n",
    "\n",
    "bookmaker['Pred_Winner'] = bookmaker.apply(prediction_from_implied_odds, axis=1)\n",
    "bookmaker['Actual_Winner'] = bookmaker.apply(actual_winner, axis=1)\n",
    "bookmaker['Brier_Score'] = bookmaker.apply(calculate_brier_score, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d61e43d",
   "metadata": {},
   "source": [
    "### Join NBA team identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad17b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_idents = pd.read_csv('Desktop/nba_conversions.csv')\n",
    "nba_idents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6601eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bookmaker_ = bookmaker\n",
    "for team in ['Home','Away']:\n",
    "    bookmaker_ = pd.merge(bookmaker_, nba_idents, \n",
    "                   left_on = f'{team}_Name', \n",
    "                   right_on = 'Team',\n",
    "                   how='left')\n",
    "\n",
    "    bookmaker_ = bookmaker_.rename(columns={\n",
    "        'AbbrA': f'{team}_AbbrA',\n",
    "        'AbbrB': f'{team}_AbbrB',\n",
    "        'City': f'{team}_City', \n",
    "        'Mascot': f'{team}_Mascot', \n",
    "        'Team': f'{team}_Team'\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae22f71",
   "metadata": {},
   "source": [
    "### Load RAPTOR scores from 538\n",
    "Downloaded from [https://data.fivethirtyeight.com/#nba-forecasts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2019586",
   "metadata": {},
   "outputs": [],
   "source": [
    "raptor = pd.read_csv('Desktop/nba_elo.csv')\n",
    "\n",
    "# reformat date to match bookmaker\n",
    "raptor['date'] = pd.to_datetime(raptor['date'], format='%Y-%m-%d').astype(str)\n",
    "\n",
    "raptor.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890fd955",
   "metadata": {},
   "source": [
    "### Join Bookmaker and RAPTOR data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a1fd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "full = pd.merge(bookmaker_, raptor, \n",
    "            left_on=['Home_AbbrB','Away_AbbrB','date'],\n",
    "            right_on=['team1','team2','date'],\n",
    "            how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4014d406",
   "metadata": {},
   "outputs": [],
   "source": [
    "full = full.drop_duplicates()\n",
    "full = full.sort_values(by=['Game_Time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf943f5",
   "metadata": {},
   "source": [
    "### Examine Missing Data\n",
    "FiveThirtyEight does not provide data for preseason. Also, there are a couple games that are missing a Predicted Winner (because the bookmaker gave the teams equal odds). We remove all of these games but keep both regular season and playoffs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3111e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "ms.matrix(full);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf73a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "full = full.dropna(subset=['raptor1_pre','Pred_Winner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d652e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "full.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946c61bc",
   "metadata": {},
   "source": [
    "### Reorder and Drop Columns and Save to Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c162f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "full = full[[\n",
    "    'date','Home_AbbrB','Away_AbbrB','Bookmaker',\n",
    "    'Home_Amer','Away_Amer',\n",
    "    'Home_Imp','Away_Imp','Total_Imp','Full_Payout', \n",
    "    'Pred_Winner','Actual_Winner','Brier_Score',\n",
    "    'elo1_pre','elo2_pre',\n",
    "    'elo_prob1','elo_prob2',\n",
    "    'raptor1_pre','raptor2_pre',\n",
    "    'raptor_prob1','raptor_prob2',\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887533c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc317a7e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "full.to_pickle('nba-{season}-with-raptor.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
