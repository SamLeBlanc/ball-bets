{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36609ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "import chromedriver_autoinstaller\n",
    "\n",
    "import time\n",
    "import random\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "import missingno as ms\n",
    "from plotnine import *\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 999)\n",
    "pd.set_option('display.max_columns', 999)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8db097",
   "metadata": {},
   "source": [
    "## Contents:\n",
    "- Set Selenium options\n",
    "- Scrape OddsPortal URLs of all NBA Games in a season [saved to .txt file]\n",
    "- Scrape Bookmaker data from OP URLs into dataframe [saved to pickle]\n",
    "- Transform Bookmaker dataframe\n",
    "- Join NBA team identifiers (needed to join to RAPTOR)\n",
    "- Join RAPTOR scores downloaded from 538"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad010f92",
   "metadata": {},
   "source": [
    "### Set Selenium Options \n",
    "Important! so that OddsPortal is signed in to Sam's account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4deec536",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_path = r'C:\\Users\\sleblanc\\AppData\\Local\\Google\\Chrome\\User Data'\n",
    "profile_name = 'Profile 3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3be19655",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_chrome_options():\n",
    "    \"\"\"\n",
    "    Set options for the Chrome webdriver used by Selenium.\n",
    "    Most importantly, set the user data directory and user profile to utilize Chrome's saved passwords.\n",
    "    ----------------\n",
    "    Returns: webdriver.ChromeOptions: Configured Chrome webdriver options.\n",
    "    \"\"\"\n",
    "    profile_path = r'C:\\Users\\sleblanc\\AppData\\Local\\Google\\Chrome\\User Data'\n",
    "    profile_name = 'Profile 3'\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(f'user-data-dir={profile_path}')\n",
    "    options.add_argument(f'--profile-directory={profile_name}')\n",
    "    return options\n",
    "\n",
    "\n",
    "def kill_chrome_processes():\n",
    "    \"\"\"\n",
    "    Terminate all running Chrome processes.\n",
    "    Selenium may encounter issues if there are multiple Chrome instances running,\n",
    "    especially when using a Chrome profile for saved passwords. This function\n",
    "    terminates all Chrome processes (using the subprocess module), including\n",
    "    previous Selenium instances.\n",
    "    \"\"\"\n",
    "    subprocess.call(\"TASKKILL /f  /IM  CHROME.EXE\", stdout=subprocess.DEVNULL, stderr=subprocess.STDOUT)\n",
    "\n",
    "\n",
    "def get_webdriver():\n",
    "    \"\"\"\n",
    "    Instantiate and return a Selenium Chrome webdriver with custom options.\n",
    "    ----------------\n",
    "    Returns:\n",
    "        webdriver.Chrome: Configured Chrome webdriver instance.\n",
    "        False if an exception occurs during instantiation.\n",
    "    Note:\n",
    "        The webdriver must be downloaded and added to PATH. See:\n",
    "        https:/selenium-python.readthedocs.io/installation.html\n",
    "    \"\"\"\n",
    "    try:\n",
    "        chromedriver_autoinstaller.install()\n",
    "        kill_chrome_processes()\n",
    "        options = set_chrome_options()\n",
    "        driver = webdriver.Chrome(options=options)\n",
    "        return driver\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13406918",
   "metadata": {},
   "source": [
    "## Scrape OddsPortal URLs of All NBA Games in a Season\n",
    "Done: [saved to .txt file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4eb81d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_page(driver, retries=5):\n",
    "    \"\"\"\n",
    "    Load the content of a page by scrolling to the bottom multiple times.\n",
    "    ----------------\n",
    "    Args:\n",
    "        driver (webdriver): The Selenium webdriver instance to interact with the page.\n",
    "        retries (int, optional): The number of times to scroll to the bottom. Defaults to 5.\n",
    "    \"\"\"\n",
    "    for _ in range(retries):\n",
    "        driver.execute_script(\"window.scrollTo(0, 0);\")\n",
    "        time.sleep(1)\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(1)\n",
    "\n",
    "def extract_game_hrefs(driver, season, remove_hrefs):\n",
    "    \"\"\"\n",
    "    Extract the game links from the current page of the NBA season results.\n",
    "    ----------------\n",
    "    Args:\n",
    "        driver (webdriver): The Selenium webdriver instance to interact with the page.\n",
    "        season (str): The NBA season in the format \"YYYY-YYYY\".\n",
    "        remove_hrefs (list): A list of URLs to exclude from the result.\n",
    "    Returns:\n",
    "        set: A set of URLs for individual games in the specified NBA season.\n",
    "    \"\"\"\n",
    "    hrefs = [x.get_attribute(\"href\") for x in driver.find_elements_by_tag_name(\"a\")]\n",
    "    if season == '2022-2023':\n",
    "        game_hrefs = set(x for x in hrefs if '/basketball/usa/nba/' in x and x not in remove_hrefs)\n",
    "    else:\n",
    "        game_hrefs = set(x for x in hrefs if f'nba-{season}' in x and x not in remove_hrefs)\n",
    "    return game_hrefs\n",
    "\n",
    "\n",
    "def click_next_page(driver):\n",
    "    \"\"\"\n",
    "    Click the \"Next\" button to navigate to the next page of the NBA season results.\n",
    "    ----------------\n",
    "    Args: driver (webdriver): The Selenium webdriver instance to interact with the page.\n",
    "    Raises: Exception: If the \"Next\" button is not found on the page.\n",
    "    \"\"\"\n",
    "    driver.find_elements_by_class_name(\"h-max\")[1].click()\n",
    "\n",
    "\n",
    "def scrape_season(season, max_pages=30):\n",
    "    \"\"\"\n",
    "    Scrape game links from the NBA season results page on OddsPortal.\n",
    "    ----------------\n",
    "    Args:\n",
    "        season (str, optional): The NBA season to scrape. Defaults to \"2021-2022\".\n",
    "        max_pages (int, optional): Maximum number of pages to scrape. Defaults to 30.\n",
    "    Returns:\n",
    "        list: A list of URLs for individual games in the specified NBA season.\n",
    "    \"\"\"\n",
    "    all_game_urls = set()\n",
    "    url_base = \"https://www.oddsportal.com/basketball/usa/\"\n",
    "    \n",
    "    if season == '2022-2023':\n",
    "        url = f\"{url_base}nba/results/#\"\n",
    "    else:\n",
    "        url = f\"{url_base}nba-{season}/results/#\"\n",
    "        \n",
    "    driver = get_webdriver()\n",
    "    driver.get(url)\n",
    "\n",
    "    for n in range(1, max_pages + 1):    \n",
    "        time.sleep(0.5 + 2 * random.random())\n",
    "        load_page(driver)\n",
    "\n",
    "        remove_hrefs = [\n",
    "            f'https://www.oddsportal.com/basketball/usa/nba-{season}/results/#',\n",
    "            f'https://www.oddsportal.com/basketball/usa/nba-{season}/results/',\n",
    "            f'https://www.oddsportal.com/basketball/usa/nba-{season}/',\n",
    "            f'https://www.oddsportal.com/basketball/usa/nba-{season}/standings/',\n",
    "            f'https://www.oddsportal.com/basketball/usa/nba/results/#',\n",
    "            f'https://www.oddsportal.com/basketball/usa/nba/results/',\n",
    "            f'https://www.oddsportal.com/basketball/usa/nba/',\n",
    "            f'https://www.oddsportal.com/basketball/usa/nba/standings/',\n",
    "        ]\n",
    "\n",
    "        game_urls = extract_game_hrefs(driver, season, remove_hrefs)\n",
    "        all_game_urls.update(game_urls)\n",
    "\n",
    "        print(f'Page {n} Finished: Added {len(game_urls)} new games. Total Games: {len(all_game_urls)}')\n",
    "                \n",
    "        try:\n",
    "            click_next_page(driver)\n",
    "        except Exception as e:\n",
    "            print(f\"Next Page Error; closing driver\")\n",
    "            driver.quit()\n",
    "            return list(all_game_urls)\n",
    "\n",
    "    driver.quit()\n",
    "    return list(all_game_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4d97ea",
   "metadata": {},
   "source": [
    "## Scrape ðŸ¥·"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94714aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "for season in ['2018-2019','2019-2020','2020-2021','2021-2022','2022-2023']:\n",
    "    \n",
    "    print(f\"\\n {season} \\n\")\n",
    "\n",
    "    all_game_urls = scrape_season(season)\n",
    "\n",
    "    # save url list to text file for later\n",
    "    with open(f'all_game_urls_{season}.txt', 'w') as file:\n",
    "        for item in all_game_urls:\n",
    "            file.write(item + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d5b606",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "## Create Bookmaker dataframes from OP URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a88a4baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def game_to_df(driver, game_info_xpath, odds_xpath):\n",
    "    \"\"\"\n",
    "    Extract game and odds information from a webpage and return it as a DataFrame.\n",
    "    ----------------\n",
    "    Args:\n",
    "        driver (WebDriver): Selenium WebDriver instance.\n",
    "        game_info_xpath (str): XPath for the game information element.\n",
    "        odds_xpath (str): XPath for the odds information element.\n",
    "    Returns: \n",
    "        pd.DataFrame: DataFrame containing game and odds information.\n",
    "    \"\"\"\n",
    "\n",
    "    def get_game_info():\n",
    "        \"\"\"\n",
    "        Extract game information from the webpage using the given XPath.\n",
    "        ----------------\n",
    "        Returns: dict: Dictionary containing game information.\n",
    "        \"\"\"\n",
    "        game_info_el = driver.find_element(By.XPATH, game_info_xpath)\n",
    "        game_info_list = game_info_el.text.split('\\n')\n",
    "\n",
    "        format_string = '%A, %d %b %Y, %H:%M'\n",
    "        game_time = game_info_list[5]\n",
    "\n",
    "        return {\n",
    "            'Game_Time' : datetime.strptime(game_time, format_string).strftime('%Y-%m-%d %H:%M'),\n",
    "            'Home_Name' : game_info_list[0],\n",
    "            'Away_Name' : game_info_list[3],\n",
    "            'Game_Result' : game_info_list[7],\n",
    "            'Home_Score' : game_info_list[1],\n",
    "            'Away_Score' : game_info_list[4],\n",
    "        }\n",
    "\n",
    "    def get_odds_info():\n",
    "        \"\"\"\n",
    "        Extract odds information from the webpage using the given XPath.\n",
    "        ----------------\n",
    "        Returns: list: List containing odds information.\n",
    "        \"\"\"\n",
    "        odds_el = driver.find_element(By.XPATH, odds_xpath)\n",
    "\n",
    "        odds_list = odds_el.text.split('\\n')\n",
    "        odds_list = [x for x in odds_list if x != 'BONUS']\n",
    "        odds_list = odds_list[4:odds_list.index('Average')]\n",
    "\n",
    "        return odds_list\n",
    "\n",
    "    def get_odds_array(odds_list):\n",
    "        \"\"\"\n",
    "        Convert the odds list into a NumPy array.\n",
    "        ----------------\n",
    "        Args: odds_list (list): List containing odds information.\n",
    "        Returns: np.array: NumPy array of odds information, or False if the list length is not divisible by 4.\n",
    "        \"\"\"\n",
    "        if len(odds_list) % 4 == 0:\n",
    "            rows = int(len(odds_list) / 4)\n",
    "            odds_array = np.array(odds_list).reshape(rows, 4)\n",
    "            return odds_array\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    # get the game info and odds\n",
    "    try:\n",
    "        game_summary = get_game_info()    \n",
    "        odds_list = get_odds_info()    \n",
    "        odds_array = get_odds_array(odds_list)\n",
    "\n",
    "        # create dataframe of bookmaker odds \n",
    "        df = pd.DataFrame(odds_array, columns=['Bookmaker', 'Home_Amer', 'Away_Amer', 'Full_Payout'])\n",
    "\n",
    "        # set the game summary values for all bookmaker rows in dataframe\n",
    "        for key in game_summary:\n",
    "            df[key] = game_summary[key]\n",
    "\n",
    "        # reorder dataframe columns\n",
    "        df = df[[\n",
    "            'Game_Time', 'Home_Name', 'Away_Name', 'Game_Result', 'Home_Score', 'Away_Score',\n",
    "            'Bookmaker', 'Home_Amer', 'Away_Amer', 'Full_Payout']]\n",
    "\n",
    "        return df\n",
    "    except:\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3c21d1",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "## Scrape ðŸ¥·"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4d65ccbe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 2018-2019 \n",
      "\n",
      "\n",
      " 1380 games \n",
      "\n",
      "Finished scraping 0 games out of 1380\n",
      "Finished scraping 10 games out of 1380\n",
      "Finished scraping 20 games out of 1380\n",
      "Finished scraping 30 games out of 1380\n",
      "Finished scraping 40 games out of 1380\n",
      "Finished scraping 50 games out of 1380\n",
      "Finished scraping 60 games out of 1380\n",
      "Finished scraping 70 games out of 1380\n",
      "Finished scraping 80 games out of 1380\n",
      "Finished scraping 90 games out of 1380\n",
      "Finished scraping 100 games out of 1380\n",
      "Finished scraping 110 games out of 1380\n",
      "Finished scraping 120 games out of 1380\n",
      "Finished scraping 130 games out of 1380\n",
      "Finished scraping 140 games out of 1380\n",
      "Finished scraping 150 games out of 1380\n",
      "Finished scraping 160 games out of 1380\n",
      "Finished scraping 170 games out of 1380\n",
      "Finished scraping 180 games out of 1380\n",
      "Finished scraping 190 games out of 1380\n",
      "Finished scraping 200 games out of 1380\n",
      "Finished scraping 210 games out of 1380\n",
      "Finished scraping 220 games out of 1380\n",
      "Finished scraping 230 games out of 1380\n",
      "Finished scraping 240 games out of 1380\n",
      "Finished scraping 250 games out of 1380\n",
      "Finished scraping 260 games out of 1380\n",
      "Finished scraping 270 games out of 1380\n",
      "Finished scraping 280 games out of 1380\n",
      "Finished scraping 290 games out of 1380\n",
      "Finished scraping 300 games out of 1380\n",
      "Finished scraping 310 games out of 1380\n",
      "Finished scraping 320 games out of 1380\n",
      "Finished scraping 330 games out of 1380\n",
      "Finished scraping 340 games out of 1380\n",
      "Finished scraping 350 games out of 1380\n",
      "Finished scraping 360 games out of 1380\n",
      "Finished scraping 370 games out of 1380\n",
      "Finished scraping 380 games out of 1380\n",
      "Finished scraping 390 games out of 1380\n",
      "Finished scraping 400 games out of 1380\n",
      "Finished scraping 410 games out of 1380\n",
      "Finished scraping 420 games out of 1380\n",
      "Finished scraping 430 games out of 1380\n",
      "Finished scraping 440 games out of 1380\n",
      "Finished scraping 450 games out of 1380\n",
      "Finished scraping 460 games out of 1380\n",
      "Finished scraping 470 games out of 1380\n",
      "Finished scraping 480 games out of 1380\n",
      "Finished scraping 490 games out of 1380\n",
      "Skipped: https://www.oddsportal.com/basketball/usa/nba-2018-2019/toronto-raptors-milwaukee-bucks-tpirxifr/\n",
      "Finished scraping 500 games out of 1380\n",
      "Finished scraping 510 games out of 1380\n",
      "Finished scraping 520 games out of 1380\n",
      "Finished scraping 530 games out of 1380\n",
      "Finished scraping 540 games out of 1380\n",
      "Finished scraping 550 games out of 1380\n",
      "Finished scraping 560 games out of 1380\n",
      "Finished scraping 570 games out of 1380\n",
      "Finished scraping 580 games out of 1380\n",
      "Finished scraping 590 games out of 1380\n",
      "Finished scraping 600 games out of 1380\n",
      "Finished scraping 610 games out of 1380\n",
      "Finished scraping 620 games out of 1380\n",
      "Finished scraping 630 games out of 1380\n",
      "Finished scraping 640 games out of 1380\n",
      "Finished scraping 650 games out of 1380\n",
      "Finished scraping 660 games out of 1380\n",
      "Finished scraping 670 games out of 1380\n",
      "Finished scraping 680 games out of 1380\n",
      "Finished scraping 690 games out of 1380\n",
      "Finished scraping 700 games out of 1380\n",
      "Finished scraping 710 games out of 1380\n",
      "Finished scraping 720 games out of 1380\n",
      "Finished scraping 730 games out of 1380\n",
      "Finished scraping 740 games out of 1380\n",
      "Finished scraping 750 games out of 1380\n",
      "Finished scraping 760 games out of 1380\n",
      "Finished scraping 770 games out of 1380\n",
      "Finished scraping 780 games out of 1380\n",
      "Finished scraping 790 games out of 1380\n",
      "Finished scraping 800 games out of 1380\n",
      "Finished scraping 810 games out of 1380\n",
      "Finished scraping 820 games out of 1380\n",
      "Finished scraping 830 games out of 1380\n",
      "Finished scraping 840 games out of 1380\n",
      "Finished scraping 850 games out of 1380\n",
      "Finished scraping 860 games out of 1380\n",
      "Finished scraping 870 games out of 1380\n",
      "Finished scraping 880 games out of 1380\n",
      "Finished scraping 890 games out of 1380\n",
      "Finished scraping 900 games out of 1380\n",
      "Finished scraping 910 games out of 1380\n",
      "Finished scraping 920 games out of 1380\n",
      "Finished scraping 930 games out of 1380\n",
      "Finished scraping 940 games out of 1380\n",
      "Finished scraping 950 games out of 1380\n",
      "Finished scraping 960 games out of 1380\n",
      "Finished scraping 970 games out of 1380\n",
      "Finished scraping 980 games out of 1380\n",
      "Finished scraping 990 games out of 1380\n",
      "Finished scraping 1000 games out of 1380\n",
      "Finished scraping 1010 games out of 1380\n",
      "Finished scraping 1020 games out of 1380\n",
      "Finished scraping 1030 games out of 1380\n",
      "Finished scraping 1040 games out of 1380\n",
      "Finished scraping 1050 games out of 1380\n",
      "Finished scraping 1060 games out of 1380\n",
      "Finished scraping 1070 games out of 1380\n",
      "Finished scraping 1080 games out of 1380\n",
      "Finished scraping 1090 games out of 1380\n",
      "Finished scraping 1100 games out of 1380\n",
      "Finished scraping 1110 games out of 1380\n",
      "Finished scraping 1120 games out of 1380\n",
      "Finished scraping 1130 games out of 1380\n",
      "Finished scraping 1140 games out of 1380\n",
      "Finished scraping 1150 games out of 1380\n",
      "Finished scraping 1160 games out of 1380\n",
      "Finished scraping 1170 games out of 1380\n",
      "Finished scraping 1180 games out of 1380\n",
      "Finished scraping 1190 games out of 1380\n",
      "Finished scraping 1200 games out of 1380\n",
      "Finished scraping 1210 games out of 1380\n",
      "Finished scraping 1220 games out of 1380\n",
      "Finished scraping 1230 games out of 1380\n",
      "Finished scraping 1240 games out of 1380\n",
      "Finished scraping 1250 games out of 1380\n",
      "Finished scraping 1260 games out of 1380\n",
      "Finished scraping 1270 games out of 1380\n",
      "Finished scraping 1280 games out of 1380\n",
      "Finished scraping 1290 games out of 1380\n",
      "Finished scraping 1300 games out of 1380\n",
      "Finished scraping 1310 games out of 1380\n",
      "Finished scraping 1320 games out of 1380\n",
      "Finished scraping 1330 games out of 1380\n",
      "Skipped: https://www.oddsportal.com/basketball/usa/nba-2018-2019/washington-wizards-phoenix-suns-rFCaLgXp/\n",
      "Finished scraping 1340 games out of 1380\n",
      "Finished scraping 1350 games out of 1380\n",
      "Finished scraping 1360 games out of 1380\n",
      "Finished scraping 1370 games out of 1380\n",
      "\n",
      " 2019-2020 \n",
      "\n",
      "\n",
      " 1251 games \n",
      "\n",
      "Finished scraping 0 games out of 1251\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [34]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinished scraping \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m games out of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(all_game_urls)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Scrape Home/Away odds data\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/#home-away;1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Random sleep so no DDOS\u001b[39;00m\n\u001b[0;32m     27\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandom())\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:333\u001b[0m, in \u001b[0;36mWebDriver.get\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, url):\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;124;03m    Loads a web page in the current browser session.\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 333\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGET\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43murl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:319\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    316\u001b[0m         params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession_id\n\u001b[0;32m    318\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_value(params)\n\u001b[1;32m--> 319\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommand_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver_command\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[0;32m    321\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py:374\u001b[0m, in \u001b[0;36mRemoteConnection.execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    372\u001b[0m data \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mdump_json(params)\n\u001b[0;32m    373\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_url, path)\n\u001b[1;32m--> 374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py:397\u001b[0m, in \u001b[0;36mRemoteConnection._request\u001b[1;34m(self, method, url, body)\u001b[0m\n\u001b[0;32m    394\u001b[0m     body \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep_alive:\n\u001b[1;32m--> 397\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    399\u001b[0m     statuscode \u001b[38;5;241m=\u001b[39m resp\u001b[38;5;241m.\u001b[39mstatus\n\u001b[0;32m    400\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\request.py:78\u001b[0m, in \u001b[0;36mRequestMethods.request\u001b[1;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_encode_url(\n\u001b[0;32m     75\u001b[0m         method, url, fields\u001b[38;5;241m=\u001b[39mfields, headers\u001b[38;5;241m=\u001b[39mheaders, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39murlopen_kw\n\u001b[0;32m     76\u001b[0m     )\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_encode_body(\n\u001b[0;32m     79\u001b[0m         method, url, fields\u001b[38;5;241m=\u001b[39mfields, headers\u001b[38;5;241m=\u001b[39mheaders, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39murlopen_kw\n\u001b[0;32m     80\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\request.py:170\u001b[0m, in \u001b[0;36mRequestMethods.request_encode_body\u001b[1;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[0m\n\u001b[0;32m    167\u001b[0m extra_kw[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mupdate(headers)\n\u001b[0;32m    168\u001b[0m extra_kw\u001b[38;5;241m.\u001b[39mupdate(urlopen_kw)\n\u001b[1;32m--> 170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murlopen(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mextra_kw)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\poolmanager.py:375\u001b[0m, in \u001b[0;36mPoolManager.urlopen\u001b[1;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[0;32m    373\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    374\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 375\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(method, u\u001b[38;5;241m.\u001b[39mrequest_uri, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    377\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m redirect_location:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\connectionpool.py:699\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    696\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_proxy(conn)\n\u001b[0;32m    698\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 699\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    700\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    701\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    703\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    707\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    710\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    711\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    712\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n\u001b[0;32m    713\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\connectionpool.py:445\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    440\u001b[0m             httplib_response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m    441\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    442\u001b[0m             \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    443\u001b[0m             \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    444\u001b[0m             \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m--> 445\u001b[0m             \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    446\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\connectionpool.py:440\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    438\u001b[0m     \u001b[38;5;66;03m# Python 3\u001b[39;00m\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 440\u001b[0m         httplib_response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    441\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    442\u001b[0m         \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    443\u001b[0m         \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    444\u001b[0m         \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m    445\u001b[0m         six\u001b[38;5;241m.\u001b[39mraise_from(e, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\http\\client.py:1374\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1372\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1373\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1374\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1375\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1376\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\http\\client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\http\\client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# load url list from file\n",
    "\n",
    "all_game_urls = []\n",
    "\n",
    "for season in ['2018-2019','2019-2020','2020-2021','2021-2022','2022-2023']:\n",
    "    \n",
    "    print(f\"\\n {season} \\n\")\n",
    "\n",
    "    with open(f'all_game_urls_{season}.txt', 'r') as file:\n",
    "        all_game_urls = [line.strip() for line in file.readlines()]\n",
    "        \n",
    "    print(f\"\\n {len(all_game_urls)} games \\n\")\n",
    "\n",
    "    # Element XPATHs, subject to change\n",
    "    game_info_xpath = \"/html/body/div[1]/div/div[1]/div/main/div[2]/div[3]\"\n",
    "    odds_xpath = \"/html/body/div[1]/div/div[1]/div/main/div[2]/div[4]\"\n",
    "\n",
    "    driver = get_webdriver()\n",
    "    bookmaker = pd.DataFrame()\n",
    "    for i, url in enumerate(all_game_urls):\n",
    "        if i % 10 == 0: print(f\"Finished scraping {i} games out of {len(all_game_urls)}\")\n",
    "\n",
    "        # Scrape Home/Away odds data\n",
    "        driver.get(url + '/#home-away;1')\n",
    "\n",
    "        # Random sleep so no DDOS\n",
    "        time.sleep(1 + 2*random.random())\n",
    "\n",
    "        # Get bookmaker data from single game into dataframe\n",
    "        df_ = game_to_df(driver, game_info_xpath, odds_xpath)\n",
    "\n",
    "        if len(df_) < 1:\n",
    "            print(\"Skipped:\", url)\n",
    "        else:\n",
    "            # Concat with full dataframe\n",
    "            bookmaker = pd.concat([bookmaker, df_])\n",
    "            bookmaker = bookmaker.drop_duplicates()\n",
    "            bookmaker.to_pickle(f'bookmaker_{season}.pkl')\n",
    "\n",
    "    bookmaker = bookmaker.drop_duplicates()\n",
    "    bookmaker.to_pickle(f'bookmaker_{season}.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc9605b",
   "metadata": {},
   "source": [
    "### 2020-2021 Skips\n",
    "\n",
    "Skipped: https://www.oddsportal.com/basketball/usa/nba-2020-2021/houston-rockets-utah-jazz-GKC2XbS9/\n",
    "Skipped: https://www.oddsportal.com/basketball/usa/nba-2020-2021/memphis-grizzlies-san-antonio-spurs-GtlhmSW6/\n",
    "Skipped: https://www.oddsportal.com/basketball/usa/nba-2020-2021/portland-trail-blazers-atlanta-hawks-rsXfJ2zH/\n",
    "Skipped: https://www.oddsportal.com/basketball/usa/nba-2020-2021/dallas-mavericks-utah-jazz-KfxdwcKJ/\n",
    "Skipped: https://www.oddsportal.com/basketball/usa/nba-2020-2021/memphis-grizzlies-los-angeles-clippers-INe1o4Ct/\n",
    "Skipped: https://www.oddsportal.com/basketball/usa/nba-2020-2021/toronto-raptors-charlotte-hornets-W86EQrg4/\n",
    "Skipped: https://www.oddsportal.com/basketball/usa/nba-2020-2021/phoenix-suns-philadelphia-76ers-dflFs7gF/\n",
    "Skipped: https://www.oddsportal.com/basketball/usa/nba-2020-2021/detroit-pistons-new-york-knicks-6XicM4qS/\n",
    "Skipped: https://www.oddsportal.com/basketball/usa/nba-2020-2021/san-antonio-spurs-houston-rockets-2RyzOQLo/\n",
    "\n",
    "### 2021-2022 Skips\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1360f0f2",
   "metadata": {},
   "source": [
    "## Transform Bookmaker Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508b9fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def implied_odds_from_american(american_odds):\n",
    "    \"\"\"\n",
    "    Calculate implied odds from American odds.\n",
    "    ----------------\n",
    "    Args: american_odds (int or str): American odds value.\n",
    "    Returns: float: Implied odds.\n",
    "    Raises: ValueError: If the absolute value of American odds is less than 100.\n",
    "    \"\"\"\n",
    "    american_odds = int(american_odds)\n",
    "    if abs(american_odds) < 100:\n",
    "        raise ValueError(f\"American odds must always have absolute value over 100. Supplied odds: {american_odds}\")\n",
    "\n",
    "    if american_odds < 0:\n",
    "        return -american_odds / (-american_odds + 100)\n",
    "    return 100 / (american_odds + 100)\n",
    "\n",
    "def prediction_from_implied_odds(row):\n",
    "    \"\"\"\n",
    "    Predict the winning team based on implied odds.\n",
    "    ----------------\n",
    "    Args: row (dict): A dictionary containing 'Home_Imp' and 'Away_Imp' keys.\n",
    "    Returns: str or None: 'Home' if Home has higher implied odds, 'Away' if Away has higher implied odds, and None if tied.\n",
    "    \"\"\"\n",
    "    home_implied_odds = row['Home_Imp']\n",
    "    away_implied_odds = row['Away_Imp']\n",
    "    \n",
    "    if home_implied_odds > away_implied_odds:\n",
    "        return 'Home'\n",
    "    elif away_implied_odds > home_implied_odds:\n",
    "        return 'Away'\n",
    "    return None\n",
    "\n",
    "def actual_winner(row):\n",
    "    \"\"\"\n",
    "    Determine the actual winner based on the scores.\n",
    "    ----------------\n",
    "    Args: row (dict): A dictionary containing 'Home_Score' and 'Away_Score' keys.\n",
    "    Returns: str or None: 'Home' if Home has a higher score, 'Away' if Away has a higher score, and None if tied.\n",
    "    \"\"\"\n",
    "    home_score = int(row['Home_Score'])\n",
    "    away_score = int(row['Away_Score'])\n",
    "    \n",
    "    if home_score > away_score:\n",
    "        return 'Home'\n",
    "    elif away_score > home_score:\n",
    "        return 'Away'\n",
    "    return None\n",
    "\n",
    "def calculate_brier_score(row):\n",
    "    \"\"\"\n",
    "    Calculate the Brier score for the given row.\n",
    "    ----------------\n",
    "    Args: row (dict): A dictionary containing 'Pred_Winner', 'Actual_Winner', 'Home_Imp', and 'Away_Imp' keys.\n",
    "    Returns: float or np.nan: Brier score if both prediction and actual winner are not None, otherwise np.nan.\n",
    "    \"\"\"\n",
    "    predicted_winner = row['Pred_Winner']\n",
    "    actual_winner = row['Actual_Winner']\n",
    "    \n",
    "    if not predicted_winner or not actual_winner:\n",
    "        return np.nan\n",
    "\n",
    "    if predicted_winner == actual_winner:\n",
    "        return (row[f'{predicted_winner}_Imp'] - 1) ** 2\n",
    "    return row[f'{predicted_winner}_Imp'] ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a58edc8",
   "metadata": {},
   "source": [
    "### Apply transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd588cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bookmaker['date'] = pd.to_datetime(bookmaker['Game_Time'], format='%Y-%m-%d %H:%M').dt.date\n",
    "bookmaker['date'] = bookmaker['date'].apply(lambda x: x.strftime('%Y-%m-%d'))\n",
    "\n",
    "bookmaker['Home_Imp'] = bookmaker['Home_Amer'].apply(implied_odds_from_american)\n",
    "bookmaker['Away_Imp'] = bookmaker['Away_Amer'].apply(implied_odds_from_american)\n",
    "bookmaker['Total_Imp'] = bookmaker['Home_Imp'] + bookmaker['Away_Imp']\n",
    "\n",
    "bookmaker['Pred_Winner'] = bookmaker.apply(prediction_from_implied_odds, axis=1)\n",
    "bookmaker['Actual_Winner'] = bookmaker.apply(actual_winner, axis=1)\n",
    "bookmaker['Brier_Score'] = bookmaker.apply(calculate_brier_score, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d61e43d",
   "metadata": {},
   "source": [
    "### Join NBA team identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad17b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_idents = pd.read_csv('Desktop/nba_conversions.csv')\n",
    "nba_idents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6601eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bookmaker_ = bookmaker\n",
    "for team in ['Home','Away']:\n",
    "    bookmaker_ = pd.merge(bookmaker_, nba_idents, \n",
    "                   left_on = f'{team}_Name', \n",
    "                   right_on = 'Team',\n",
    "                   how='left')\n",
    "\n",
    "    bookmaker_ = bookmaker_.rename(columns={\n",
    "        'AbbrA': f'{team}_AbbrA',\n",
    "        'AbbrB': f'{team}_AbbrB',\n",
    "        'City': f'{team}_City', \n",
    "        'Mascot': f'{team}_Mascot', \n",
    "        'Team': f'{team}_Team'\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae22f71",
   "metadata": {},
   "source": [
    "### Load RAPTOR scores from 538\n",
    "Downloaded from [https://data.fivethirtyeight.com/#nba-forecasts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2019586",
   "metadata": {},
   "outputs": [],
   "source": [
    "raptor = pd.read_csv('Desktop/nba_elo.csv')\n",
    "\n",
    "# reformat date to match bookmaker\n",
    "raptor['date'] = pd.to_datetime(raptor['date'], format='%Y-%m-%d').astype(str)\n",
    "\n",
    "raptor.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890fd955",
   "metadata": {},
   "source": [
    "### Join Bookmaker and RAPTOR data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a1fd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "full = pd.merge(bookmaker_, raptor, \n",
    "            left_on=['Home_AbbrB','Away_AbbrB','date'],\n",
    "            right_on=['team1','team2','date'],\n",
    "            how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4014d406",
   "metadata": {},
   "outputs": [],
   "source": [
    "full = full.drop_duplicates()\n",
    "full = full.sort_values(by=['Game_Time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf943f5",
   "metadata": {},
   "source": [
    "### Examine Missing Data\n",
    "FiveThirtyEight does not provide data for preseason. Also, there are a couple games that are missing a Predicted Winner (because the bookmaker gave the teams equal odds). We remove all of these games but keep both regular season and playoffs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3111e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "ms.matrix(full);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf73a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "full = full.dropna(subset=['raptor1_pre','Pred_Winner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d652e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "full.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946c61bc",
   "metadata": {},
   "source": [
    "### Reorder and Drop Columns and Save to Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c162f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "full = full[[\n",
    "    'date','Home_AbbrB','Away_AbbrB','Bookmaker',\n",
    "    'Home_Amer','Away_Amer',\n",
    "    'Home_Imp','Away_Imp','Total_Imp','Full_Payout', \n",
    "    'Pred_Winner','Actual_Winner','Brier_Score',\n",
    "    'elo1_pre','elo2_pre',\n",
    "    'elo_prob1','elo_prob2',\n",
    "    'raptor1_pre','raptor2_pre',\n",
    "    'raptor_prob1','raptor_prob2',\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887533c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc317a7e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "full.to_pickle('nba-{season}-with-raptor.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
